{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fb12f7f-a7b0-4722-abd0-cd8c476619f1",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8d0da42-0ad1-46a6-8670-57c4f1367c45",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13d6fc5c-0c78-463d-852c-9173258dc0c7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/marcusvillena/opt/anaconda3/lib/python3.9/site-packages (22.3)\n",
      "Collecting pip\n",
      "  Downloading pip-22.3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 22.3\n",
      "    Uninstalling pip-22.3:\n",
      "      Successfully uninstalled pip-22.3\n",
      "Successfully installed pip-22.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a8d046f-92fa-43cf-9f42-1be79f302470",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bash: /Users/marcusvillena/miniconda.sh: No such file or directory\n",
      "zsh:source:1: no such file or directory: /Users/marcusvillena/miniconda/bin/activate\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - tensorflow-deps\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://conda.anaconda.org/apple/osx-64\n",
      "  - https://conda.anaconda.org/apple/noarch\n",
      "  - https://repo.anaconda.com/pkgs/main/osx-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/osx-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!bash ~/miniconda.sh -b -p $HOME/miniconda\n",
    "!source ~/miniconda/bin/activate\n",
    "!conda install -c apple tensorflow-deps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b1bc98-1ecd-4510-9b25-c3c8a5b5e9ab",
   "metadata": {},
   "source": [
    "# Lecture Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c2836c-9211-4a9b-88f0-9549dee6366d",
   "metadata": {},
   "source": [
    "* You can use `tensorflow` package to create and train a neural network\n",
    "* To use tensorflow you need to first set a seed. It ensures that your model always returns the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51a9b219-9922-4e85-84ae-11e6c36fd75e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bd5337-fc18-4384-94a5-e2a2ceaafbd2",
   "metadata": {},
   "source": [
    " * To create the model you need to first define a model as a sequence of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b61c5cc-f086-4203-9a49-3a2bb76f77ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdd27f4-73ff-4e8c-a503-06b093633c61",
   "metadata": {},
   "source": [
    "\n",
    "* Then you can define the input and hidden layer and add them to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2f0cf32-3b79-43ef-9543-ada8f4f80450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, InputLayer\n",
    "input_layer = InputLayer(input_shape=(2,))\n",
    "model.add(input_layer)\n",
    "hidden_layer = Dense(3)\n",
    "model.add(hidden_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0597da-a183-4fda-bc24-221a4720bcfc",
   "metadata": {},
   "source": [
    "* The number of input layer neurons (corresponding to 2 features) is determined using the `input_shape` argument, and the hidden layer has 3 neurons.\n",
    "<br>\n",
    "* You can also add additional hidden layers with different numbers of neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cebea19d-b7c3-4917-a8b8-b2cc37182bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_hidden_layer = Dense(5)\n",
    "model.add(second_hidden_layer)\n",
    "third_hidden_layer = Dense(2)\n",
    "model.add(third_hidden_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8843bdac-e4e3-4e8b-aa11-3412266b3df5",
   "metadata": {},
   "source": [
    "* Output layer is added at the last step\n",
    "    * **Note.** If your problem is regression you don't need to set an activation argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dae8a051-a2fd-4fcc-9356-7f80f7f904aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer = Dense(1, activation = 'sigmoid')\n",
    "model.add(output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf8a1b7-c642-44f8-aa21-50bd4827f1cb",
   "metadata": {},
   "source": [
    "\n",
    "* After creating the model you should configure it using `compile` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e4036ee-7369-4bd8-9671-6280aad6348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57138a28-02d8-47b2-af3d-bbf743a5aaa2",
   "metadata": {},
   "source": [
    "* `binary_crossentropy` is a loss function that is minimized in the training process. It is an appropriate choice for classification with two classes.\n",
    "* Other common choices are:\n",
    "    * `categorical_crossentropy` for classification with multiple classes.\n",
    "    * `mean_absolute_error` for regression problems.\n",
    "\n",
    " <br><br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627c2302-692d-42bd-b639-2dd7181c3e44",
   "metadata": {},
   "source": [
    "* Training of the model is done using `fit` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96ba616d-a1c5-430d-9b36-f674d1e11581",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5028\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5017\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5015\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5018\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5019\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5010\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5017\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5006\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5036\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15fb6dac0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('data_science_score.csv')\n",
    "\n",
    "X = data.loc[:, ['Theoretical knowledge', 'Programming skill']]\n",
    "y = data.loc[:, ['Class']]\n",
    "\n",
    "model.fit(X, y, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1d4799-bf58-4896-a69b-f43e556ff4dc",
   "metadata": {},
   "source": [
    "  <br><br><br>\n",
    "\n",
    "* Finally you can predict the class of new data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0cc5a3da-a311-4dc0-b84d-7374b1c6d572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 115ms/step\n",
      "[[0.9018012 ]\n",
      " [0.27099553]\n",
      " [0.27099553]]\n"
     ]
    }
   ],
   "source": [
    "new_samples = [[10, 4], [1,10], [1,10]]\n",
    "predictions = model.predict(new_samples)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72ec3f9b-1a51-458a-a5c0-768a08743f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "roc_auc_score([1,0,1], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c8bc5f-c332-4917-8309-540b40ac67bb",
   "metadata": {},
   "source": [
    " * It returns the probability of class 1 for each sample.\n",
    " \n",
    "  <br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab1262a-499f-4d4f-a160-b6e5d5ee6b6e",
   "metadata": {},
   "source": [
    "# Example: Iris classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caf71a9-3920-4a43-9bcb-571dc9b3ef94",
   "metadata": {},
   "source": [
    "* Now consider the iris classification problem. There are three different classes of setosa, versicolor, and virginica.\n",
    "* To use a neural network for such a problem we first need to break it into the binary classifications.\n",
    "    1. Is the sample a setosa or not?\n",
    "    2. Is the sample a versicolor or not?\n",
    "    3. Is the sample a virginica or not?\n",
    "* So we need to first convert the outcome.\n",
    "<br><br><br>\n",
    "* We can use `LabelEncoder` in `sklearn` package and `to_categorical` in `keras` package to encode each outcome value into a list of 3 binary values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88d1d216-14e9-4506-8d32-9413027b1856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_transform output only: \n",
      " [0 1 2 1] \n",
      "\n",
      "to_categorical output: \n",
      " [[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "y = ['sertosa', 'versicolor', 'virginica', 'versicolor']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "print(\"fit_transform output only: \\n\", y, \"\\n\")\n",
    "\n",
    "y = to_categorical(y)\n",
    "print(\"to_categorical output: \\n\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d558cdf7-b622-4035-8cee-a193cbbb0a11",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "* After encoding the outcome you can creaate the model\n",
    "    * For each sample we have three outcomes, so the output layer must include 3 neurons.\n",
    "    * Each neuron obtains a value for one class using a linear combination of its inputs.\n",
    "    * Finally **softmax** function uses these values to assign a probability to each of the classes.\n",
    "    * This function is an alternative to the sigmoid function in classification problems with more than 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c69e5076-f95b-4751-b67b-eb131fa86f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, InputLayer\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    InputLayer(\n",
    "        input_shape=(4,)))\n",
    "\n",
    "model.add(\n",
    "    Dense(8))\n",
    "\n",
    "model.add(\n",
    "    Dense(\n",
    "        3,\n",
    "        activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e71132-4b70-4c10-88b5-e0454d827c5b",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Example: Iris classification (final code):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81943536-786a-4659-a172-90244fedda55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 15ms/step - loss: 0.9602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 09:11:22.229902: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1574b96a0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, InputLayer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "y = to_categorical(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    InputLayer(\n",
    "        input_shape=(4,)))\n",
    "\n",
    "model.add(\n",
    "    Dense(8))\n",
    "\n",
    "model.add(\n",
    "    Dense(3, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5ab926-199e-4a4e-b083-65377bd69177",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "* Using `predict` with this model we can obtain the probability of each of the three classes for each sample.\n",
    "* The class with the greatest probability is selected as the sample class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f5f1ba7-1a32-4896-a876-e51b4b87b07e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step\n",
      "[[2.7130116e-03 1.6068180e-01 8.3660525e-01]\n",
      " [1.0659104e-03 4.6380732e-02 9.5255339e-01]\n",
      " [3.5052004e-03 1.9123439e-01 8.0526036e-01]\n",
      " [9.6058246e-04 3.5840515e-02 9.6319890e-01]\n",
      " [5.8103609e-04 2.3947569e-02 9.7547138e-01]\n",
      " [5.2310461e-03 1.5879881e-01 8.3597016e-01]\n",
      " [3.5187204e-03 8.7108165e-02 9.0937316e-01]\n",
      " [5.6369212e-03 1.8069714e-01 8.1366587e-01]\n",
      " [1.7989579e-03 1.8980572e-02 9.7922051e-01]\n",
      " [3.5566173e-04 1.0235693e-02 9.8940873e-01]\n",
      " [2.0393590e-03 1.5175998e-01 8.4620064e-01]\n",
      " [5.9326296e-04 4.0598441e-02 9.5880830e-01]\n",
      " [4.9338276e-03 1.8019781e-01 8.1486839e-01]\n",
      " [1.6961087e-03 1.6054856e-02 9.8224902e-01]\n",
      " [2.2490295e-03 2.6910808e-02 9.7084010e-01]\n",
      " [1.1637800e-03 3.9889086e-02 9.5894718e-01]\n",
      " [2.0662909e-03 3.2786727e-02 9.6514702e-01]\n",
      " [4.0559444e-04 3.5200946e-02 9.6439350e-01]\n",
      " [7.5822687e-03 1.9900332e-01 7.9341435e-01]\n",
      " [3.6507039e-03 1.7283407e-01 8.2351524e-01]\n",
      " [6.1573419e-03 1.7023392e-01 8.2360876e-01]\n",
      " [6.3265488e-04 4.2033207e-02 9.5733404e-01]\n",
      " [3.1104831e-03 1.9189124e-01 8.0499834e-01]\n",
      " [8.6137909e-04 1.6872684e-02 9.8226595e-01]\n",
      " [8.0077525e-04 2.2255151e-02 9.7694403e-01]\n",
      " [5.3942914e-04 3.9523274e-02 9.5993733e-01]\n",
      " [3.9747781e-03 1.8359064e-01 8.1243461e-01]\n",
      " [4.2568450e-03 2.0270391e-01 7.9303932e-01]\n",
      " [3.0023055e-03 5.3226948e-02 9.4377077e-01]\n",
      " [6.4198737e-04 3.7890632e-02 9.6146739e-01]\n",
      " [4.4639796e-04 3.7798017e-02 9.6175557e-01]\n",
      " [4.2083738e-03 1.7286202e-01 8.2292974e-01]\n",
      " [1.9109972e-04 1.4626704e-02 9.8518223e-01]\n",
      " [1.4763009e-03 4.5811310e-02 9.5271242e-01]\n",
      " [2.6617046e-03 1.4431947e-01 8.5301888e-01]\n",
      " [1.8128497e-03 3.3182018e-02 9.6500510e-01]\n",
      " [1.9360122e-03 6.5582447e-02 9.3248159e-01]\n",
      " [7.4126446e-03 1.9830209e-01 7.9428536e-01]\n",
      " [1.5128676e-03 1.4158269e-02 9.8432887e-01]\n",
      " [1.6583345e-03 4.1528948e-02 9.5681274e-01]\n",
      " [1.1351637e-03 3.3580493e-02 9.6528441e-01]\n",
      " [2.2487633e-03 2.7880495e-02 9.6987075e-01]\n",
      " [4.0956973e-03 1.9397572e-01 8.0192864e-01]\n",
      " [1.4639173e-04 1.3434340e-02 9.8641926e-01]\n",
      " [2.2192488e-03 5.6539204e-02 9.4124156e-01]\n",
      " [5.0677324e-04 1.8030562e-02 9.8146272e-01]\n",
      " [1.3647589e-03 2.3609022e-02 9.7502613e-01]\n",
      " [9.1206643e-04 1.8398644e-02 9.8068923e-01]\n",
      " [3.7133039e-03 1.8016113e-01 8.1612569e-01]\n",
      " [1.0020363e-03 2.3471102e-02 9.7552687e-01]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "845d2960-1d20-4098-ab38-fc6c28386ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8135212418300654"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "#use roc_auc_score() for binary classification\n",
    "roc_auc_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f2b311-42ad-4dcf-b10f-613370035420",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Image Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e84bbf-7e5c-4975-872e-b06b4fdb14eb",
   "metadata": {},
   "source": [
    "* ...\n",
    "* In practice, images can be represented using a matrix of numbers (2 dimensional array or list of lists). Each number in the matrix encodes the color of one of the pixels in the image.\n",
    "* For a gray scale images these numbers can be in range 0 to 16 for example, to represent the colors between black(0) and white(16).\n",
    "* See an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59677774-b219-4fc7-9100-e79d1008eac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = [[0, 0, 5, 13],\n",
    "         [0, 0, 13, 15],\n",
    "         [0, 3, 15, 2],\n",
    "         [0, 4, 12, 0]]\n",
    "plt.gray()\n",
    "plt.matshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbec66b5-04d9-4e9c-a946-e17eb872ac69",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "* `sklearn` package includes an image dataset of the handwritten digits.\n",
    "* Each image has 8 × 8 = 64 pixels and is labeled with its corresponding digit (0 to 9).\n",
    "* This data can be load in python as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52b3e2d8-9536-479e-8139-3a0a98942dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X[0]: \n",
      " [ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.\n",
      " 15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.\n",
      "  0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.\n",
      "  0.  0.  0.  0.  6. 13. 10.  0.  0.  0.] \n",
      "\n",
      "y[0]: \n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "images = digits.images\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "print(\"X[0]: \\n\", X[0],\"\\n\")\n",
    "print(\"y[0]: \\n\", y[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e875a68-a789-4fa6-9bed-8d98ac6d382a",
   "metadata": {},
   "source": [
    "* `X` includes the list of 64 features for each sample(image) in the data, and `y` includes the label.\n",
    "* You can also get the image matrix and plot the image as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77c49c3e-7e05-4611-b6ba-b73292c1202b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "images = digits.images\n",
    "\n",
    "plt.gray()\n",
    "plt.matshow(images[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263219f0-8cdc-4b23-bde9-2446526e04ba",
   "metadata": {},
   "source": [
    "* `images` is the list of image matrices\n",
    "* Note that the values of the image matrix and the values of the feature list are the same.\n",
    "\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fa70b1-c46d-49ed-9411-f71e2e6e20ff",
   "metadata": {},
   "source": [
    "### Example: Digit image classification\n",
    "* Lets train a neural network model to classify the digit images in one of the ten classes (0 to 9).\n",
    "* The input layer should include 64 neurons and output layer 10 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "774b711c-dea4-4bc2-b7c5-7414266229d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "images = digits.images\n",
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "233712e2-7b7a-4fa9-bfaa-e93d94b1523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, InputLayer\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "model = Sequential()\n",
    "\n",
    "input_layer = InputLayer(input_shape=(64,))\n",
    "model.add(input_layer)\n",
    "\n",
    "hidden_layer = Dense(5)\n",
    "model.add(hidden_layer)\n",
    "\n",
    "output_layer = Dense(10, activation='softmax')\n",
    "model.add(output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6950c805-8bff-4d3a-a664-b56b4b85bd49",
   "metadata": {},
   "source": [
    "* To train the model we first need to convert the digit labels to 10 binary values using to categorical function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6b25cea4-a6b2-4ef2-8280-4358917291d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa070d39-526a-4ef3-91f1-fcacb31f2e51",
   "metadata": {},
   "source": [
    "* Then the model can be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "46b5e62f-7d55-4824-8c26-5b0dd628ad6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 4/45 [=>............................] - ETA: 0s - loss: 0.7502 - accuracy: 0.7656 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 08:47:20.321072: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 1s 12ms/step - loss: 0.4270 - accuracy: 0.8664\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.3778 - accuracy: 0.8803\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - 0s 10ms/step - loss: 0.3583 - accuracy: 0.8921\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - 0s 10ms/step - loss: 0.3325 - accuracy: 0.8970\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.3152 - accuracy: 0.9033\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - 0s 10ms/step - loss: 0.2969 - accuracy: 0.9151\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - 0s 10ms/step - loss: 0.2831 - accuracy: 0.9179\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - 0s 10ms/step - loss: 0.2685 - accuracy: 0.9235\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - 0s 10ms/step - loss: 0.2556 - accuracy: 0.9255\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - 0s 10ms/step - loss: 0.2452 - accuracy: 0.9290\n",
      "1797\n",
      "1437\n",
      "360\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.3212 - accuracy: 0.9111\n",
      "[0.32124045491218567, 0.9111111164093018]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 08:47:25.244048: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(X_train, y_train, epochs = 10)\n",
    "\n",
    "print(len(y))\n",
    "print(len(y_train))\n",
    "print(len(y_test))\n",
    "\n",
    "performance = model.evaluate(X_test, y_test)\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1ca440-9c2a-47ea-91b4-40ece6d8fb59",
   "metadata": {},
   "source": [
    "* We set the `metrics` argument to check the `accuracy` of the model.\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "* We can evaluate the model performance on the testing set using the `evaluate` method.\n",
    "* It returns a list with two items. The first item is the value of the loss function, and the second is the accuracy of the model (between 0 and 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "94a19f9c-c223-4841-b4da-16e98e1d30d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/56 [====>.........................] - ETA: 0s - loss: 0.3027 - accuracy: 0.8892"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 08:39:30.195752: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 1s 9ms/step - loss: 0.2911 - accuracy: 0.9011\n",
      "[0.29109105467796326, 0.901123583316803]\n"
     ]
    }
   ],
   "source": [
    "performance = model.evaluate(X_test, y_test)\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cb74fb7f-006c-49bf-a964-d1f7015abfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0168 - accuracy: 1.0000\n",
      "[[ 0.  0.  3. 14.  3.  0.  0.  0.  0.  0. 13. 13.  0.  0.  0.  0.  0.  0.\n",
      "  16.  7.  0.  0.  0.  0.  0.  5. 16.  3.  0.  0.  0.  0.  0.  3. 16.  7.\n",
      "   4.  2.  0.  0.  0.  4. 16. 16. 16. 16.  7.  0.  0.  1. 14. 15.  4. 11.\n",
      "  15.  0.  0.  0.  5. 14. 16. 12.  6.  0.]]\n"
     ]
    }
   ],
   "source": [
    "performance = model.evaluate(X_test[[0]], y_test[[0]])\n",
    "\n",
    "print(X_test[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9b0cdbc1-c98d-45cb-a434-6c7db0547847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  3. 14.  3.  0.  0.  0.]\n",
      " [ 0.  0. 13. 13.  0.  0.  0.  0.]\n",
      " [ 0.  0. 16.  7.  0.  0.  0.  0.]\n",
      " [ 0.  5. 16.  3.  0.  0.  0.  0.]\n",
      " [ 0.  3. 16.  7.  4.  2.  0.  0.]\n",
      " [ 0.  4. 16. 16. 16. 16.  7.  0.]\n",
      " [ 0.  1. 14. 15.  4. 11. 15.  0.]\n",
      " [ 0.  0.  5. 14. 16. 12.  6.  0.]]\n"
     ]
    }
   ],
   "source": [
    "plt.gray()\n",
    "plt.matshow(X_test[[0]].reshape(8,8))\n",
    "plt.show()\n",
    "\n",
    "print(X_test[[0]].reshape(8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "16c3b9fe-0c80-4bb6-97d5-3fbbc519b8da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X7 = [[0, 0, 0, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 1, 1, 1, 1, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 1, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 1, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 1, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 1, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 1, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0, 0]]\n",
    "\n",
    "y7 = [0,0,0,0,0,0,1,0]\n",
    "\n",
    "plt.gray()\n",
    "plt.matshow(X7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "babfae9b-b1bd-4001-a1fa-6b4b06470355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0168 - accuracy: 1.0000\n",
      "[[ 0.  0.  3. 14.  3.  0.  0.  0.  0.  0. 13. 13.  0.  0.  0.  0.  0.  0.\n",
      "  16.  7.  0.  0.  0.  0.  0.  5. 16.  3.  0.  0.  0.  0.  0.  3. 16.  7.\n",
      "   4.  2.  0.  0.  0.  4. 16. 16. 16. 16.  7.  0.  0.  1. 14. 15.  4. 11.\n",
      "  15.  0.  0.  0.  5. 14. 16. 12.  6.  0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "performance = model.evaluate(X_test[[0]], y_test[[0]])\n",
    "\n",
    "print(X_test[[0]])\n",
    "print(y_test[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "566e31d3-e7c4-415f-a739-307dac55136f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 0 1 1 1 1 0 0]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0]]\n",
      "[0 0 0 0 0 0 1 0]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/marcusvillena/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/training.py\", line 1727, in test_function  *\n        return step_function(self, iterator)\n    File \"/Users/marcusvillena/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/training.py\", line 1713, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/marcusvillena/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/training.py\", line 1701, in run_step  **\n        outputs = model.test_step(data)\n    File \"/Users/marcusvillena/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/training.py\", line 1665, in test_step\n        y_pred = self(x, training=False)\n    File \"/Users/marcusvillena/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/marcusvillena/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 64), found shape=(None, 8)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [152], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(X7)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(y7)\n\u001b[0;32m---> 12\u001b[0m performance \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX7\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43my7\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/wz/gr7z7mvd2vlg27d3y8x5dzwh0000gn/T/__autograph_generated_filefbpkkyse.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/marcusvillena/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/training.py\", line 1727, in test_function  *\n        return step_function(self, iterator)\n    File \"/Users/marcusvillena/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/training.py\", line 1713, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/marcusvillena/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/training.py\", line 1701, in run_step  **\n        outputs = model.test_step(data)\n    File \"/Users/marcusvillena/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/training.py\", line 1665, in test_step\n        y_pred = self(x, training=False)\n    File \"/Users/marcusvillena/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/marcusvillena/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 64), found shape=(None, 8)\n"
     ]
    }
   ],
   "source": [
    "#performance = model.evaluate([X7], [[0,0,0,0,0,0,1,0]])\n",
    "\n",
    "#print(X_test[[0]].reshape(8,8))\n",
    "#print(y_test[[0]])\n",
    "import numpy as np\n",
    "X7 = np.array(X7)\n",
    "y7 = np.array(y7)\n",
    "print(X7)\n",
    "print(y7)\n",
    "\n",
    "\n",
    "performance = model.evaluate([[X7]], [[y7]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
